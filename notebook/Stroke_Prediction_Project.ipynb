{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "declaration",
   "metadata": {},
   "source": [
    "# Declaration of Originality\n",
    "\n",
    "**Student Name:** [Your Name]  \n",
    "**Student ID:** [Your ID]  \n",
    "**Class:** [Your Class]  \n",
    "\n",
    "I declare that this assignment is my own work and has been completed in accordance with the school's academic integrity policy.\n",
    "\n",
    "**Use of Generative AI:**\n",
    "- [ ] I did not use any Generative AI tools\n",
    "- [ ] I used Generative AI tools (Claude, ChatGPT, etc.) for: ___________\n",
    "\n",
    "**Signature:** ___________  \n",
    "**Date:** ___________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning - Model Selection\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Machine Learning - Models (ONLY scikit-learn allowed)\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Machine Learning - Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, auc\n",
    ")\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "problem_statement",
   "metadata": {},
   "source": [
    "# 2. Problem Statement & Dataset\n",
    "\n",
    "## 2.1 Business Problem\n",
    "\n",
    "**Problem:** Predicting stroke risk in patients to enable early intervention and prevention\n",
    "\n",
    "**Why it matters:**\n",
    "- Strokes are a leading cause of death and disability worldwide\n",
    "- Early detection allows preventive measures (lifestyle changes, medication)\n",
    "- Reduces healthcare costs through prevention vs treatment\n",
    "- Improves patient quality of life through timely intervention\n",
    "\n",
    "**Target Audience:** Healthcare providers, clinics, hospitals\n",
    "\n",
    "## 2.2 Dataset Information\n",
    "\n",
    "**Source:** Kaggle - Stroke Prediction Dataset  \n",
    "**URL:** https://www.kaggle.com/datasets/jawairia123/stroke-prediction-dataset/data  \n",
    "**Size:** 5,110 samples (rows) × 12 features (columns)  \n",
    "**Target Variable:** `stroke` (0 = No stroke, 1 = Stroke)  \n",
    "**Problem Type:** Binary Classification  \n",
    "\n",
    "**Features:**\n",
    "1. `id` - Unique identifier\n",
    "2. `gender` - Male/Female/Other\n",
    "3. `age` - Age of patient\n",
    "4. `hypertension` - 0 = no hypertension, 1 = has hypertension\n",
    "5. `heart_disease` - 0 = no heart disease, 1 = has heart disease\n",
    "6. `ever_married` - Yes/No\n",
    "7. `work_type` - Type of work (Private, Self-employed, Govt_job, children, Never_worked)\n",
    "8. `Residence_type` - Urban/Rural\n",
    "9. `avg_glucose_level` - Average glucose level in blood\n",
    "10. `bmi` - Body mass index\n",
    "11. `smoking_status` - formerly smoked, never smoked, smokes, Unknown\n",
    "12. `stroke` - TARGET: 0 = no stroke, 1 = stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data",
   "metadata": {},
   "source": [
    "## 2.3 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "FILE_PATH = 'healthcare-dataset-stroke-data.csv'\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(f\"\\nNumber of samples: {df.shape[0]:,}\")\n",
    "print(f\"Number of features: {df.shape[1]}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Display first few rows\n",
    "display(df.head())\n",
    "\n",
    "# Display data types and non-null counts\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic_stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for numerical features\n",
    "print(\"Numerical Features Summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Summary for categorical features\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nCategorical Features Summary:\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda_section",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Purpose:** Understand the data, identify patterns, detect outliers, and discover relationships between features and target variable.\n",
    "\n",
    "## 3.1 Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing_values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"Missing Values Summary:\")\n",
    "    display(missing_df)\n",
    "    \n",
    "    # Visualize missing values\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(missing_df.index, missing_df['Missing Count'])\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Number of Missing Values')\n",
    "    plt.title('Missing Values by Feature')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"✅ No missing values found!\")\n",
    "\n",
    "# INTERPRETATION: \n",
    "# TODO: Write your interpretation here\n",
    "# Example: \"BMI has 201 missing values (3.9%). This represents a small portion of data.\n",
    "# We will handle this in the data preparation phase by imputing with median value.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "target_dist",
   "metadata": {},
   "source": [
    "## 3.2 Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "target_distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "target_counts = df['stroke'].value_counts()\n",
    "target_percent = df['stroke'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Target Variable Distribution:\")\n",
    "print(f\"No Stroke (0): {target_counts[0]:,} ({target_percent[0]:.2f}%)\")\n",
    "print(f\"Stroke (1): {target_counts[1]:,} ({target_percent[1]:.2f}%)\")\n",
    "print(f\"\\nImbalance Ratio: {target_counts[0]/target_counts[1]:.2f}:1\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count plot\n",
    "axes[0].bar(['No Stroke', 'Stroke'], target_counts.values, color=['green', 'red'])\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Stroke Distribution (Count)')\n",
    "for i, v in enumerate(target_counts.values):\n",
    "    axes[0].text(i, v + 50, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(target_counts.values, labels=['No Stroke', 'Stroke'], autopct='%1.1f%%', \n",
    "            colors=['green', 'red'], startangle=90)\n",
    "axes[1].set_title('Stroke Distribution (Percentage)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# INTERPRETATION:\n",
    "# TODO: Write your interpretation here\n",
    "# Example: \"The dataset is highly imbalanced with only 4.9% stroke cases (249 out of 5,110).\n",
    "# This imbalance suggests we should:\n",
    "# 1. Focus on recall as primary metric (to minimize missing stroke cases)\n",
    "# 2. Consider using class weights in our models\n",
    "# 3. Be cautious about accuracy as a metric - a model predicting all 'No Stroke' \n",
    "#    would achieve 95% accuracy but be useless!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical_dist",
   "metadata": {},
   "source": [
    "## 3.3 Numerical Features Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical_distributions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns (exclude 'id' as it's just an identifier)\n",
    "numerical_cols = ['age', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "# Distribution plots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 12))\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    # Histogram\n",
    "    axes[i, 0].hist(df[col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[i, 0].set_xlabel(col)\n",
    "    axes[i, 0].set_ylabel('Frequency')\n",
    "    axes[i, 0].set_title(f'{col} Distribution')\n",
    "    axes[i, 0].axvline(df[col].mean(), color='red', linestyle='--', label=f'Mean: {df[col].mean():.2f}')\n",
    "    axes[i, 0].axvline(df[col].median(), color='green', linestyle='--', label=f'Median: {df[col].median():.2f}')\n",
    "    axes[i, 0].legend()\n",
    "    \n",
    "    # Box plot\n",
    "    axes[i, 1].boxplot(df[col].dropna(), vert=True)\n",
    "    axes[i, 1].set_ylabel(col)\n",
    "    axes[i, 1].set_title(f'{col} Box Plot (Outlier Detection)')\n",
    "    axes[i, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Outlier detection using IQR method\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Outlier Analysis (IQR Method):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in numerical_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_percent = (outlier_count / len(df)) * 100\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "    print(f\"  Valid range: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "    print(f\"  Outliers detected: {outlier_count} ({outlier_percent:.2f}%)\")\n",
    "    if outlier_count > 0:\n",
    "        print(f\"  Outlier values range: [{outliers[col].min():.2f}, {outliers[col].max():.2f}]\")\n",
    "\n",
    "# INTERPRETATION:\n",
    "# TODO: Write your interpretation here\n",
    "# Example: \"Age shows a right-skewed distribution with most patients between 40-80 years.\n",
    "# BMI has some outliers above 50, representing extreme obesity cases which are medically\n",
    "# relevant for stroke prediction - we should keep these.\n",
    "# Glucose level shows high variability, which is expected in stroke patients.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correlation_analysis",
   "metadata": {},
   "source": [
    "## 3.4 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns including binary features for correlation\n",
    "corr_cols = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'stroke']\n",
    "correlation_matrix = df[corr_cols].corr()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1)\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature correlation with target\n",
    "print(\"\\nCorrelation with Target Variable (Stroke):\")\n",
    "target_corr = correlation_matrix['stroke'].sort_values(ascending=False)\n",
    "print(target_corr)\n",
    "\n",
    "# Visualize correlation with target\n",
    "plt.figure(figsize=(10, 6))\n",
    "target_corr[:-1].plot(kind='barh', color='steelblue')\n",
    "plt.xlabel('Correlation with Stroke')\n",
    "plt.title('Feature Correlation with Target Variable')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# INTERPRETATION:\n",
    "# TODO: Write your interpretation here\n",
    "# Example: \"Age shows strongest positive correlation with stroke (0.25), indicating older\n",
    "# patients have higher risk. Hypertension and heart disease also show positive correlation.\n",
    "# All correlations are relatively weak (<0.3), suggesting non-linear relationships which\n",
    "# tree-based models (Random Forest, Gradient Boosting) might capture better than linear models.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "target_vs_features",
   "metadata": {},
   "source": [
    "## 3.5 Target Variable vs Key Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "target_vs_numerical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features vs Target\n",
    "numerical_features = ['age', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for i, col in enumerate(numerical_features):\n",
    "    # Box plot grouped by stroke\n",
    "    df.boxplot(column=col, by='stroke', ax=axes[i])\n",
    "    axes[i].set_xlabel('Stroke (0=No, 1=Yes)')\n",
    "    axes[i].set_ylabel(col)\n",
    "    axes[i].set_title(f'{col} vs Stroke')\n",
    "    plt.sca(axes[i])\n",
    "    plt.xticks([1, 2], ['No Stroke', 'Stroke'])\n",
    "\n",
    "plt.suptitle('')  # Remove auto-generated title\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical comparison\n",
    "print(\"\\nMean Values by Stroke Status:\")\n",
    "print(\"=\"*60)\n",
    "for col in numerical_features:\n",
    "    no_stroke_mean = df[df['stroke']==0][col].mean()\n",
    "    stroke_mean = df[df['stroke']==1][col].mean()\n",
    "    difference = stroke_mean - no_stroke_mean\n",
    "    percent_diff = (difference / no_stroke_mean) * 100\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  No Stroke: {no_stroke_mean:.2f}\")\n",
    "    print(f\"  Stroke: {stroke_mean:.2f}\")\n",
    "    print(f\"  Difference: {difference:+.2f} ({percent_diff:+.1f}%)\")\n",
    "\n",
    "# INTERPRETATION:\n",
    "# TODO: Write your interpretation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "target_vs_categorical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features vs Target\n",
    "categorical_features = ['gender', 'hypertension', 'heart_disease', 'ever_married', \n",
    "                        'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(categorical_features):\n",
    "    # Create crosstab\n",
    "    ct = pd.crosstab(df[col], df['stroke'], normalize='index') * 100\n",
    "    \n",
    "    # Plot\n",
    "    ct.plot(kind='bar', stacked=False, ax=axes[i], color=['green', 'red'])\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Percentage (%)')\n",
    "    axes[i].set_title(f'Stroke Rate by {col}')\n",
    "    axes[i].legend(['No Stroke', 'Stroke'])\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Remove extra subplots\n",
    "for j in range(len(categorical_features), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print stroke rates by category\n",
    "print(\"\\nStroke Rate by Category:\")\n",
    "print(\"=\"*60)\n",
    "for col in categorical_features:\n",
    "    print(f\"\\n{col}:\")\n",
    "    stroke_rate = df.groupby(col)['stroke'].mean() * 100\n",
    "    counts = df.groupby(col)['stroke'].value_counts().unstack(fill_value=0)\n",
    "    for category in stroke_rate.index:\n",
    "        print(f\"  {category}: {stroke_rate[category]:.2f}% ({counts.loc[category, 1] if 1 in counts.columns else 0} strokes out of {counts.loc[category].sum()} total)\")\n",
    "\n",
    "# INTERPRETATION:\n",
    "# TODO: Write your interpretation here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda_summary",
   "metadata": {},
   "source": [
    "## 3.6 EDA Summary & Key Insights\n",
    "\n",
    "**TODO: Summarize your key findings from EDA**\n",
    "\n",
    "Example structure:\n",
    "\n",
    "### Key Findings:\n",
    "1. **Class Imbalance:** Only 4.9% stroke cases - need to focus on recall metric\n",
    "2. **Missing Data:** BMI has 201 missing values (3.9%) - will impute with median\n",
    "3. **Strong Predictors:** Age, hypertension, heart disease show clear association with stroke\n",
    "4. **Outliers:** BMI outliers represent medically relevant cases - will keep them\n",
    "5. **Feature Relationships:** Weak linear correlations suggest tree-based models may perform better\n",
    "\n",
    "### Implications for Modeling:\n",
    "- Use recall as primary evaluation metric\n",
    "- Consider class weights or resampling techniques\n",
    "- Focus on Random Forest and Gradient Boosting (handle non-linear relationships)\n",
    "- Feature engineering: create age groups, BMI categories, risk scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_prep",
   "metadata": {},
   "source": [
    "# 4. Data Preparation\n",
    "\n",
    "## 4.1 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handle_missing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Handle missing BMI values\n",
    "print(\"Before imputation:\")\n",
    "print(f\"Missing BMI values: {df_clean['bmi'].isnull().sum()}\")\n",
    "\n",
    "# TODO: Impute missing BMI values with median\n",
    "# Justification: Using median instead of mean because BMI has outliers\n",
    "bmi_median = df_clean['bmi'].median()\n",
    "df_clean['bmi'].fillna(bmi_median, inplace=True)\n",
    "\n",
    "print(f\"\\nAfter imputation:\")\n",
    "print(f\"Missing BMI values: {df_clean['bmi'].isnull().sum()}\")\n",
    "print(f\"Imputed value (median): {bmi_median:.2f}\")\n",
    "\n",
    "# Justification: \n",
    "# \"Using median (29.0) instead of mean because BMI distribution has outliers.\n",
    "# Median is more robust and represents a typical BMI value better than mean\n",
    "# which would be influenced by extreme obesity cases.\"\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(f\"\\nTotal missing values in dataset: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handle_outliers",
   "metadata": {},
   "source": [
    "## 4.2 Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outlier_decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision on outliers\n",
    "print(\"Outlier Handling Decision:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDECISION: KEEP all outliers\")\n",
    "print(\"\\nJustification:\")\n",
    "print(\"1. BMI outliers (>50) represent extreme obesity - medically relevant for stroke\")\n",
    "print(\"2. Age outliers represent very elderly patients - high stroke risk group\")\n",
    "print(\"3. Glucose outliers indicate diabetes/pre-diabetes - important stroke risk factor\")\n",
    "print(\"4. Removing these would lose valuable information about high-risk patients\")\n",
    "print(\"5. Tree-based models (our planned approach) are robust to outliers\")\n",
    "\n",
    "# No outlier removal needed - proceed with df_clean as is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_encoding",
   "metadata": {},
   "source": [
    "## 4.3 Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encode_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID column (not useful for prediction)\n",
    "df_clean = df_clean.drop('id', axis=1)\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "categorical_cols = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "print(\"Before encoding:\")\n",
    "print(f\"Number of features: {df_clean.shape[1]}\")\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# One-hot encoding (drop_first=True to avoid multicollinearity)\n",
    "df_encoded = pd.get_dummies(df_clean, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(f\"\\nAfter encoding:\")\n",
    "print(f\"Number of features: {df_encoded.shape[1]}\")\n",
    "print(f\"\\nNew feature names:\")\n",
    "print(df_encoded.columns.tolist())\n",
    "\n",
    "# Justification:\n",
    "# \"Using one-hot encoding for categorical variables to convert them into numerical format.\n",
    "# drop_first=True removes one category from each feature to prevent perfect multicollinearity\n",
    "# (dummy variable trap), which can cause issues in some models.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train_test_split",
   "metadata": {},
   "source": [
    "## 4.4 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_encoded.drop('stroke', axis=1)\n",
    "y = df_encoded['stroke']\n",
    "\n",
    "print(\"Dataset split:\")\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "\n",
    "# Split into train and test sets\n",
    "# stratify=y ensures same proportion of stroke/no-stroke in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 80% train, 20% test\n",
    "    random_state=42,     # For reproducibility\n",
    "    stratify=y          # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(\"\\nTrain set:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  Stroke distribution: {y_train.value_counts().to_dict()}\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")\n",
    "print(f\"  Stroke distribution: {y_test.value_counts().to_dict()}\")\n",
    "\n",
    "# Verify stratification worked\n",
    "train_stroke_rate = y_train.mean() * 100\n",
    "test_stroke_rate = y_test.mean() * 100\n",
    "print(f\"\\nStroke rate in train set: {train_stroke_rate:.2f}%\")\n",
    "print(f\"Stroke rate in test set: {test_stroke_rate:.2f}%\")\n",
    "print(\"✅ Stratification successful!\" if abs(train_stroke_rate - test_stroke_rate) < 1 else \"⚠️ Check stratification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modeling_section",
   "metadata": {},
   "source": [
    "# 5. Model Development\n",
    "\n",
    "## 5.1 Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model (predicts most frequent class)\n",
    "baseline = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "baseline.fit(X_train, y_train)\n",
    "y_pred_baseline = baseline.predict(X_test)\n",
    "\n",
    "print(\"BASELINE MODEL (Most Frequent Class)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_baseline):.4f}\")\n",
    "\n",
    "print(\"\\nNote: This baseline always predicts 'No Stroke'. We need to beat this!\")\n",
    "\n",
    "# This serves as our minimum benchmark - any real model must perform better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_training",
   "metadata": {},
   "source": [
    "## 5.2 Train Multiple Models\n",
    "\n",
    "We'll train 3 different algorithms and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model1_rf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Model 1 - Random Forest Classifier\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL 1: RANDOM FOREST CLASSIFIER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize and train\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',  # Handle class imbalance\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_rf_proba):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# TODO: Add your interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model2_gb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Model 2 - Gradient Boosting Classifier\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL 2: GRADIENT BOOSTING CLASSIFIER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize and train\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "y_pred_gb_proba = gb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_gb):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_gb):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_gb):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_gb):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_gb_proba):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# TODO: Add your interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model3_lr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Model 3 - Logistic Regression\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL 3: LOGISTIC REGRESSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize and train\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_pred_lr_proba = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, y_pred_lr_proba):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# TODO: Add your interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_comparison",
   "metadata": {},
   "source": [
    "## 5.3 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare_models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['Baseline', 'Random Forest', 'Gradient Boosting', 'Logistic Regression'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_baseline),\n",
    "        accuracy_score(y_test, y_pred_rf),\n",
    "        accuracy_score(y_test, y_pred_gb),\n",
    "        accuracy_score(y_test, y_pred_lr)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_test, y_pred_baseline, zero_division=0),\n",
    "        precision_score(y_test, y_pred_rf),\n",
    "        precision_score(y_test, y_pred_gb),\n",
    "        precision_score(y_test, y_pred_lr)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test, y_pred_baseline),\n",
    "        recall_score(y_test, y_pred_rf),\n",
    "        recall_score(y_test, y_pred_gb),\n",
    "        recall_score(y_test, y_pred_lr)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_test, y_pred_baseline, zero_division=0),\n",
    "        f1_score(y_test, y_pred_rf),\n",
    "        f1_score(y_test, y_pred_gb),\n",
    "        f1_score(y_test, y_pred_lr)\n",
    "    ],\n",
    "    'ROC-AUC': [\n",
    "        0.5,  # Baseline has no probability predictions\n",
    "        roc_auc_score(y_test, y_pred_rf_proba),\n",
    "        roc_auc_score(y_test, y_pred_gb_proba),\n",
    "        roc_auc_score(y_test, y_pred_lr_proba)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nMODEL COMPARISON TABLE\")\n",
    "print(\"=\"*80)\n",
    "display(model_comparison.round(4))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: All metrics\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.2\n",
    "\n",
    "axes[0].bar(x - 1.5*width, model_comparison.iloc[1][1:].values, width, label='Random Forest')\n",
    "axes[0].bar(x - 0.5*width, model_comparison.iloc[2][1:].values, width, label='Gradient Boosting')\n",
    "axes[0].bar(x + 0.5*width, model_comparison.iloc[3][1:].values, width, label='Logistic Regression')\n",
    "axes[0].set_xlabel('Metrics')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Model Performance Comparison')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Recall comparison (most important metric)\n",
    "recall_data = model_comparison[['Model', 'Recall']].sort_values('Recall', ascending=True)\n",
    "colors = ['red' if x == 'Baseline' else 'steelblue' for x in recall_data['Model']]\n",
    "axes[1].barh(recall_data['Model'], recall_data['Recall'], color=colors)\n",
    "axes[1].set_xlabel('Recall Score')\n",
    "axes[1].set_title('Recall Comparison (Primary Metric)')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Model Selection Rationale\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL SELECTION RATIONALE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTODO: Write your model selection rationale here\")\n",
    "print(\"\\nExample:\")\n",
    "print(\"Chosen Model: Random Forest\")\n",
    "print(\"Reasons:\")\n",
    "print(\"1. Highest recall (0.XX) - critical for minimizing missed stroke cases\")\n",
    "print(\"2. Best F1-Score (0.XX) - good balance between precision and recall\")\n",
    "print(\"3. Strong ROC-AUC (0.XX) - excellent discrimination ability\")\n",
    "print(\"4. Handles non-linear relationships well (as seen in EDA)\")\n",
    "print(\"5. Provides feature importance for interpretability\")\n",
    "print(\"\\nBusiness Impact: Missing a stroke case is much more costly than a false alarm,\")\n",
    "print(\"so recall is our primary metric. Random Forest achieves best recall while\")\n",
    "print(\"maintaining reasonable precision.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iteration_section",
   "metadata": {},
   "source": [
    "# 6. Iterative Model Development\n",
    "\n",
    "## 6.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create new features\n",
    "# This is where you'll add engineered features to improve model performance\n",
    "\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a copy of the encoded data\n",
    "df_fe = df_encoded.copy()\n",
    "\n",
    "# Feature 1: Age Groups\n",
    "# TODO: Create age categories\n",
    "# Example: Young (0-40), Middle (41-60), Senior (61-80), Elderly (80+)\n",
    "\n",
    "# Feature 2: BMI Categories\n",
    "# TODO: Create BMI categories\n",
    "# Example: Underweight (<18.5), Normal (18.5-25), Overweight (25-30), Obese (>30)\n",
    "\n",
    "# Feature 3: Health Risk Score\n",
    "# TODO: Combine risk factors\n",
    "# Example: hypertension + heart_disease + (age > 60) + (bmi > 30)\n",
    "\n",
    "# Feature 4: Glucose Category\n",
    "# TODO: Categorize glucose levels\n",
    "# Example: Normal (<140), Prediabetic (140-200), Diabetic (>200)\n",
    "\n",
    "print(\"\\nNew features created:\")\n",
    "print(\"TODO: List your new features here\")\n",
    "print(f\"\\nTotal features before: {df_encoded.shape[1]}\")\n",
    "print(f\"Total features after: {df_fe.shape[1]}\")\n",
    "\n",
    "# Justification:\n",
    "print(\"\\nJustification:\")\n",
    "print(\"TODO: Explain why these features should improve the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_with_fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train model with new features\n",
    "# Split data\n",
    "# X_fe = df_fe.drop('stroke', axis=1)\n",
    "# y_fe = df_fe['stroke']\n",
    "# X_train_fe, X_test_fe, y_train_fe, y_test_fe = train_test_split(\n",
    "#     X_fe, y_fe, test_size=0.2, random_state=42, stratify=y_fe)\n",
    "\n",
    "# Train Random Forest with new features\n",
    "# rf_fe = RandomForestClassifier(...)\n",
    "# rf_fe.fit(X_train_fe, y_train_fe)\n",
    "# y_pred_fe = rf_fe.predict(X_test_fe)\n",
    "\n",
    "# Compare results\n",
    "# print(\"BEFORE Feature Engineering:\")\n",
    "# print(f\"Recall: {recall_score(y_test, y_pred_rf):.4f}\")\n",
    "# print(f\"F1-Score: {f1_score(y_test, y_pred_rf):.4f}\")\n",
    "\n",
    "# print(\"\\nAFTER Feature Engineering:\")\n",
    "# print(f\"Recall: {recall_score(y_test_fe, y_pred_fe):.4f}\")\n",
    "# print(f\"F1-Score: {f1_score(y_test_fe, y_pred_fe):.4f}\")\n",
    "\n",
    "# print(\"\\nImprovement:\")\n",
    "# print(f\"Recall: {recall_score(y_test_fe, y_pred_fe) - recall_score(y_test, y_pred_rf):+.4f}\")\n",
    "\n",
    "print(\"TODO: Implement feature engineering and show improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hyperparameter_tuning",
   "metadata": {},
   "source": [
    "## 6.2 Hyperparameter Tuning\n",
    "\n",
    "**IMPORTANT:** Must use RandomizedSearchCV (NOT GridSearchCV) with max 3 values per hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tune_hyperparameters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Hyperparameter tuning with RandomizedSearchCV\n",
    "print(\"HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define parameter distribution (max 3 values per parameter)\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# TODO: Implement RandomizedSearchCV\n",
    "# rs_rf = RandomizedSearchCV(\n",
    "#     RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=20,\n",
    "#     cv=5,\n",
    "#     scoring='recall',\n",
    "#     random_state=42,\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# rs_rf.fit(X_train_fe, y_train_fe)\n",
    "\n",
    "# Best parameters and results\n",
    "# print(\"\\nBest Parameters:\", rs_rf.best_params_)\n",
    "# print(\"Best CV Recall:\", rs_rf.best_score_)\n",
    "\n",
    "print(\"TODO: Implement hyperparameter tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_evaluation",
   "metadata": {},
   "source": [
    "# 7. Final Model Evaluation\n",
    "\n",
    "## 7.1 Comprehensive Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate final tuned model\n",
    "print(\"FINAL MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Classification report\n",
    "# print(classification_report(y_test_fe, y_pred_tuned))\n",
    "\n",
    "# Confusion matrix\n",
    "# cm = confusion_matrix(y_test_fe, y_pred_tuned)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.title('Confusion Matrix - Final Model')\n",
    "# plt.show()\n",
    "\n",
    "print(\"TODO: Show final model evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric_justification",
   "metadata": {},
   "source": [
    "## 7.2 Evaluation Metric Justification\n",
    "\n",
    "**TODO: Justify your choice of evaluation metrics**\n",
    "\n",
    "Example:\n",
    "\n",
    "### Primary Metric: RECALL\n",
    "\n",
    "**Business Rationale:**\n",
    "- **Cost of False Negative (Missing Stroke):** Very High\n",
    "  - Patient doesn't receive preventive care\n",
    "  - Stroke occurs → disability, death, high treatment costs\n",
    "  - Lost opportunity for lifestyle intervention\n",
    "\n",
    "- **Cost of False Positive (False Alarm):** Low\n",
    "  - Additional medical testing\n",
    "  - Minor inconvenience\n",
    "  - Potentially discovers other health issues\n",
    "\n",
    "**Therefore:** Optimize for recall to minimize missed cases\n",
    "\n",
    "### Secondary Metrics:\n",
    "- **F1-Score:** Ensures we maintain reasonable precision\n",
    "- **ROC-AUC:** Shows overall discrimination ability\n",
    "\n",
    "### Business Impact:\n",
    "- Final recall of 0.XX means we identify XX% of stroke cases\n",
    "- In a population of 10,000, this prevents XX strokes from being missed\n",
    "- Estimated cost savings: $XXX per prevented stroke × XX cases = $XXX,XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_importance",
   "metadata": {},
   "source": [
    "## 7.3 Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show_feature_importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Show feature importance from final model\n",
    "# importances = best_model.feature_importances_\n",
    "# feature_names = X_train_fe.columns\n",
    "# feature_importance_df = pd.DataFrame({\n",
    "#     'Feature': feature_names,\n",
    "#     'Importance': importances\n",
    "# }).sort_values('Importance', ascending=False)\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.barh(feature_importance_df['Feature'][:15], feature_importance_df['Importance'][:15])\n",
    "# plt.xlabel('Importance')\n",
    "# plt.title('Top 15 Most Important Features')\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "print(\"TODO: Implement feature importance visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_model",
   "metadata": {},
   "source": [
    "# 8. Save Final Model\n",
    "\n",
    "Save the model for deployment in Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_final_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save your final model\n",
    "# with open('stroke_prediction_model.pkl', 'wb') as f:\n",
    "#     pickle.dump(best_model, f)\n",
    "\n",
    "# # Also save feature names for consistency in Streamlit\n",
    "# with open('feature_names.pkl', 'wb') as f:\n",
    "#     pickle.dump(X_train_fe.columns.tolist(), f)\n",
    "\n",
    "# print(\"✅ Model saved successfully!\")\n",
    "# print(\"Files created:\")\n",
    "# print(\"  - stroke_prediction_model.pkl\")\n",
    "# print(\"  - feature_names.pkl\")\n",
    "\n",
    "print(\"TODO: Save your final model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "development_log",
   "metadata": {},
   "source": [
    "# 9. Development Log\n",
    "\n",
    "**TODO: Document your iterative development process**\n",
    "\n",
    "Example:\n",
    "\n",
    "## Iteration 1: Baseline Models (Date: XX/XX/2025)\n",
    "- Trained 3 models: Random Forest, Gradient Boosting, Logistic Regression\n",
    "- Best: Random Forest with recall=0.XX\n",
    "- Issue: Low recall, many false negatives\n",
    "- Decision: Focus on Random Forest, add feature engineering\n",
    "\n",
    "## Iteration 2: Feature Engineering (Date: XX/XX/2025)\n",
    "- Added: Age groups, BMI categories, Health risk score, Glucose categories\n",
    "- Result: Recall improved to 0.XX (+0.XX improvement)\n",
    "- Analysis: Age groups and risk score most impactful\n",
    "- Decision: Keep all new features for final model\n",
    "\n",
    "## Iteration 3: Hyperparameter Tuning (Date: XX/XX/2025)\n",
    "- Used RandomizedSearchCV with 20 iterations\n",
    "- Tuned: n_estimators, max_depth, min_samples_split, min_samples_leaf\n",
    "- Best params: [list params]\n",
    "- Result: Recall improved to 0.XX (+0.XX improvement)\n",
    "\n",
    "## Final Model Performance\n",
    "- Model: Random Forest with feature engineering and tuned hyperparameters\n",
    "- Recall: 0.XX (primary metric)\n",
    "- F1-Score: 0.XX\n",
    "- ROC-AUC: 0.XX\n",
    "- Total improvement from baseline: +0.XX recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "1. ✅ Complete all TODO sections in this notebook\n",
    "2. ✅ Build Streamlit web application\n",
    "3. ✅ Deploy to Streamlit Cloud\n",
    "4. ✅ Prepare presentation slides\n",
    "5. ✅ Complete Word document with links and screenshots\n",
    "6. ✅ Push code to GitHub for version control evidence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
